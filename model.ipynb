{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        isic_id  target  patient_id  age_approx   sex anatom_site_general  \\\n",
      "0  ISIC_0015670       0  IP_1235828        60.0  male     lower extremity   \n",
      "1  ISIC_0015845       0  IP_8170065        60.0  male           head/neck   \n",
      "2  ISIC_0015864       0  IP_6724798        60.0  male     posterior torso   \n",
      "3  ISIC_0015902       0  IP_4111386        65.0  male      anterior torso   \n",
      "4  ISIC_0024200       0  IP_8313778        55.0  male      anterior torso   \n",
      "\n",
      "   clin_size_long_diam_mm          image_type tbp_tile_type   tbp_lv_A  ...  \\\n",
      "0                    3.04  TBP tile: close-up     3D: white  20.244422  ...   \n",
      "1                    1.10  TBP tile: close-up     3D: white  31.712570  ...   \n",
      "2                    3.40  TBP tile: close-up        3D: XP  22.575830  ...   \n",
      "3                    3.22  TBP tile: close-up        3D: XP  14.242329  ...   \n",
      "4                    2.73  TBP tile: close-up     3D: white  24.725520  ...   \n",
      "\n",
      "    lesion_id  iddx_full  iddx_1  iddx_2  iddx_3  iddx_4  iddx_5  \\\n",
      "0         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
      "1  IL_6727506     Benign  Benign     NaN     NaN     NaN     NaN   \n",
      "2         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
      "3         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
      "4         NaN     Benign  Benign     NaN     NaN     NaN     NaN   \n",
      "\n",
      "   mel_mitotic_index  mel_thick_mm  tbp_lv_dnn_lesion_confidence  \n",
      "0                NaN           NaN                     97.517282  \n",
      "1                NaN           NaN                      3.141455  \n",
      "2                NaN           NaN                     99.804040  \n",
      "3                NaN           NaN                     99.989998  \n",
      "4                NaN           NaN                     70.442510  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "data = pd.read_csv('dataset/train-metadata.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train, validation, and test sets\n",
    "train_data, temp_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=(1/3), random_state=42)\n",
    "\n",
    "#print(len(train_data), len(val_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'dataset/train-images/'\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(img_path, label):\n",
    "    img = tf.io.read_file(img_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [224, 224])\n",
    "    img = img/255.0 # Normalize pixel values [0,1]\n",
    "    return img, label\n",
    "\n",
    "def dataframe_to_dataset(dataframe, image_dir):\n",
    "    img_paths = dataframe['isic_id'].apply(lambda x: os.path.join(image_dir, x)).values\n",
    "    labels = dataframe['iddx_full'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_paths, labels))\n",
    "    dataset = dataset.map(load_images_and_labels, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = dataframe_to_dataset(train_data, image_dir).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = dataframe_to_dataset(val_data, image_dir).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = dataframe_to_dataset(test_data, image_dir).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "#print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ResNet50 model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load ResNet-50 with pre-trained weights\n",
    "\n",
    "#weights='imagenet' specifies that we want to use the weights that were learned on the ImageNet dataset\n",
    "# include_top=False removes the fully connected layer at the top of the network\n",
    "#imput_shape=(224,224,3) specifies the shape of the input image\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
